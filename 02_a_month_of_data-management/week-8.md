# Data Processing Frameworks 

# Your Mission

1. Research these Data Processing Frameworks
  * Spark 
  * Lucene
  * Kafka 
2. What were the industry problems that catalysed the creation of these frameworks? 
3. What were the design decisions driving the creation of these tools? 
4. How did each of these tools break new ground? 
5. What does an exemplar solution look like? Build one! 

# Resources: 

1. Databricks blog, any youtube video of the AMPLab, Matei Zaharia or a member of the Spark team 
2. Similarly, any content produced by the creators of these tools
3. Official documentation 
4. [Improving processing speeds on Spark](https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html)
5. [Google Borg Paper](https://research.google.com/pubs/pub43438.html?hl=es)
