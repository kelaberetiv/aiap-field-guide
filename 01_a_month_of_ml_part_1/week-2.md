# Python and Data Part II: More Complex Workflows

### Your Mission

1. Last week we set up a local reproducible DS environment with one Jupyter notebook. Now we want to extend reprodubility to multiple scripts and workflows with multiple stages. First, set up a `cookie cutter data science` style folder [https://drivendata.github.io/cookiecutter-data-science/](https://drivendata.github.io/cookiecutter-data-science/). 
2. Read [https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details](https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details) for what real-world data workflows and pipelines look like. Construct a similar multi-stage workflow either with Python scripts or upyter Notebooks. 
3. Construct a narrative and message around your analysis. 

### Resources

For Best Practices around project organisation
* www.datacarpentry.org

* www.softwarecarpentry.org

For examples of data workflows and pipelines
* [https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details](https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details)

For sources of data to mine for stories and insight. You may like to look for SG-relevant sources of data as well. 
* [http://oceansinitiative.org](http://oceansinitiative.org)

* [https://github.com/poldrack/myconnectome](https://github.com/poldrack/myconnectome)

* www.gapminder.org

### Extension Question

Find two examples of machine learning pipelines in production \(Gmail's Smart Reply and the Google Play Store Recommenders are an example\). Compare and contrast these two pipelines.

### Roundup

Be prepared to present and answer questions on your project \(chosen randomly\)

*find something useful and want to share it? submit a pull request!*
